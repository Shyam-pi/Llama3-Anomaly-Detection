{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "M_DqMfEYC71G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGkGJVyNsICT",
        "outputId": "78eeb77a-ef50-4a99-d5d2-0b9331456e68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import shutil, os, subprocess\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import joblib\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/NIH/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset reading and pre-processing"
      ],
      "metadata": {
        "id": "dyfCxwxQDAwN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69blByWpsICU",
        "outputId": "d0193a84-51bc-4503-ee0b-b35cf777a43a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-12868150f357>:6: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  sizes_df = pd.read_csv('deviceSizes.txt', sep='|', dtype=dtype_sizes)\n"
          ]
        }
      ],
      "source": [
        "dtype_gmdn = {'PrimaryDI': str}  # Replace 'first_column_name' with the actual column name\n",
        "dtype_sizes = {'PrimaryDI': str}  # Replace 'first_column_name' with the actual column name\n",
        "\n",
        "# Read the files into a DataFrame\n",
        "gmdn_df = pd.read_csv('gmdnTerms.txt', sep='|', dtype=dtype_gmdn)\n",
        "sizes_df = pd.read_csv('deviceSizes.txt', sep='|', dtype=dtype_sizes)\n",
        "\n",
        "# Remove rows where sizeType is 'Device Size Text, specify'\n",
        "sizes_df = sizes_df[sizes_df['sizeType'] != 'Device Size Text, specify']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversion factors to SI units (meters for length, kilograms for mass, liters for volume, etc.)\n",
        "conversion_factors = {\n",
        "    'Millimeter': 1e-3,\n",
        "    'Centimeter': 1e-2,\n",
        "    'Micrometer': 1e-6,\n",
        "    'Milliliter': 1e-3,\n",
        "    'Gauge': 1,  # Gauge conversion depends on the context\n",
        "    'French': 1e-3,  # French to meter (for medical devices)\n",
        "    'Square meter': 1,\n",
        "    'Inch': 0.0254,\n",
        "    'Liter': 1,\n",
        "    'Kilogram': 1,\n",
        "    'Square centimeter': 1e-4,\n",
        "    'degree': 1,  # Degrees might need context-specific conversion\n",
        "    'Gram': 1e-3,\n",
        "    'Meter': 1,\n",
        "    'Feet': 0.3048,\n",
        "    'Pound': 0.453592,\n",
        "    'Milligram': 1e-6,\n",
        "    'Nanometer': 1e-9,\n",
        "    'Fluid Ounce': 0.0295735,\n",
        "    'Square millimeter': 1e-6,\n",
        "    'Gallon': 3.78541,\n",
        "    'Yard': 0.9144,\n",
        "    'Centiliter': 1e-2,\n",
        "    'Square inch': 6.4516e-4,\n",
        "    'Quart': 0.946353,\n",
        "    'Pint': 0.473176,\n",
        "    'Microliter': 1e-6,\n",
        "    'Cubic Inch': 0.0163871,\n",
        "    'millibar': 100,\n",
        "    'Pound per Square Inch': 6894.76,\n",
        "    'Atmosphere': 101325,\n",
        "    'Femtometer': 1e-15,\n",
        "    'Decimeter': 0.1,\n",
        "    'Kilometer': 1e3,\n",
        "    'Microgram': 1e-9,\n",
        "    'Deciliter': 1e-1,\n",
        "    'Hertz': 1,  # Hertz is a frequency unit and may not be converted here\n",
        "    'KiloPascal': 1e3\n",
        "}\n",
        "\n",
        "exception_rows = []\n",
        "\n",
        "# Function to convert values to their respective SI units\n",
        "def convert_to_si(row):\n",
        "    global exception_rows\n",
        "    unit = row['size (Unit)']\n",
        "\n",
        "    try:\n",
        "        value = float(row['size (Value)'])\n",
        "    except (ValueError, TypeError):\n",
        "        exception_rows.append(row)\n",
        "        return np.nan\n",
        "\n",
        "    if pd.isna(value):\n",
        "        return np.nan\n",
        "\n",
        "    # Check if the unit is in the conversion_factors dictionary\n",
        "    if unit not in conversion_factors:\n",
        "        # Raise an error if the unit is not in the dictionary\n",
        "        raise KeyError(f\"Unit '{unit}' not found in conversion_factors dictionary\")\n",
        "\n",
        "    factor = conversion_factors[unit]\n",
        "\n",
        "    if factor is None:\n",
        "        return np.nan  # or handle the specific case\n",
        "\n",
        "    return value * factor"
      ],
      "metadata": {
        "id": "HuWD2aKo_qXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the conversion to the DataFrame\n",
        "sizes_df['size (SI Unit)'] = sizes_df.apply(convert_to_si, axis=1)"
      ],
      "metadata": {
        "id": "pjvzOfVtAa6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where 'size (SI Unit)' is NaN\n",
        "sizes_df_cleaned = sizes_df.dropna(subset=['size (SI Unit)'])"
      ],
      "metadata": {
        "id": "ujKrUOpiCPuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vectorization"
      ],
      "metadata": {
        "id": "yLJ6pq9DD_qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Get unique sizeTypes\n",
        "unique_size_types = sizes_df_cleaned['sizeType'].unique()\n",
        "\n",
        "# Initialize the new DataFrame\n",
        "vector_df = pd.DataFrame(columns=['PrimaryDI'] + list(unique_size_types))\n",
        "vector_df['PrimaryDI'] = sizes_df_cleaned['PrimaryDI'].unique()\n",
        "vector_df = vector_df.set_index('PrimaryDI')\n",
        "\n",
        "# Populate the new DataFrame\n",
        "for idx, row in tqdm(sizes_df_cleaned.iterrows(), total=len(sizes_df_cleaned), desc=\"Processing Rows\"):\n",
        "    primary_di = row['PrimaryDI']\n",
        "    size_type = row['sizeType']\n",
        "    size_value = row['size (SI Unit)']\n",
        "    vector_df.loc[primary_di, size_type] = size_value\n",
        "\n",
        "# Reset the index to make 'PrimaryDI' a normal column\n",
        "vector_df.reset_index(inplace=True)\n",
        "vector_df.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "HxFabtRkIyVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9105c543-9982-415f-fcda-078cf935dad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 100%|██████████| 1047125/1047125 [03:30<00:00, 4966.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "WbBpPvjCLzm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HELPER FUNCTIONS**"
      ],
      "metadata": {
        "id": "ulgUlcBoL5kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ensure_folder_exists(folder_name):\n",
        "    if not os.path.exists(folder_name):\n",
        "        os.makedirs(folder_name)\n",
        "\n",
        "def remove_file_if_exists(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "\n",
        "def save_model(model, folder_name, gmdncode):\n",
        "    model_filename = os.path.join(folder_name, f'{gmdncode}_iso_forest_model.pkl')\n",
        "    joblib.dump(model, model_filename)\n",
        "\n",
        "def load_model(folder_name, gmdncode):\n",
        "    model_filename = os.path.join(folder_name, f'{gmdncode}_iso_forest_model.pkl')\n",
        "    if os.path.exists(model_filename):\n",
        "        return joblib.load(model_filename)\n",
        "    else:\n",
        "        print(f\"Model for gmdncode {gmdncode} not found.\")\n",
        "        return None\n",
        "\n",
        "def save_anomalies_to_csv(anomalies_filtered, file_path):\n",
        "    anomalies_filtered.to_csv(\n",
        "        file_path,\n",
        "        mode='a',\n",
        "        header=not os.path.exists(file_path),\n",
        "        index=False\n",
        "    )\n",
        "\n",
        "def process_gmdn_codes(gmdn_df, vector_df, folder_name, file_name, mode):\n",
        "\n",
        "    # Get unique GMDNCodes\n",
        "    name_counts = gmdn_df['gmdnCode'].value_counts()\n",
        "\n",
        "    # Ensure the folder exists\n",
        "    ensure_folder_exists(folder_name)\n",
        "\n",
        "    file_path = os.path.join(folder_name, file_name)\n",
        "\n",
        "    # Delete the previous anomalies file if it exists\n",
        "    remove_file_if_exists(file_path)\n",
        "\n",
        "    # Loop over unique gmdnCode values with tqdm progress bar\n",
        "    for gmdncode in tqdm(dict(name_counts).keys(), desc=\"Processing gmdnCodes\"):\n",
        "        # Filter gmdn_df to get PrimaryDI values where gmdnCode equals the current gmdncode\n",
        "        filtered_primary_di = gmdn_df[gmdn_df['gmdnCode'] == gmdncode]['PrimaryDI']\n",
        "\n",
        "        # Convert to list\n",
        "        filtered_primary_di_list = filtered_primary_di.tolist()\n",
        "\n",
        "        # Filter vector_df based on PrimaryDI values obtained from df\n",
        "        filtered_sizes_df = vector_df[vector_df['PrimaryDI'].isin(filtered_primary_di_list)].copy()\n",
        "\n",
        "        # Neglecting GMDN Codes with set sizes less than 5\n",
        "        if filtered_sizes_df.shape[0] < 5:\n",
        "            continue\n",
        "\n",
        "        # Extract 'PrimaryDI' and the feature columns\n",
        "        primary_di = filtered_sizes_df['PrimaryDI']\n",
        "        features = filtered_sizes_df.drop(columns=['PrimaryDI'])\n",
        "\n",
        "        # Scale the feature columns\n",
        "        scaler = StandardScaler()\n",
        "        features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "        if mode == 1:\n",
        "            # Training Mode\n",
        "            iso_forest = IsolationForest(contamination=0.00001, random_state=42)\n",
        "            iso_forest.fit(features_scaled)\n",
        "\n",
        "            # Save the model\n",
        "            save_model(iso_forest, folder_name, gmdncode)\n",
        "\n",
        "        elif mode == 2:\n",
        "            # Inference Mode (load existing model)\n",
        "            iso_forest = load_model(folder_name, gmdncode)\n",
        "            if iso_forest is None:\n",
        "                raise FileNotFoundError(f\"Model for gmdnCode {gmdncode} not found.\")\n",
        "                continue\n",
        "\n",
        "        # Predict anomalies\n",
        "        anomaly_scores = iso_forest.decision_function(features_scaled)\n",
        "        anomaly_labels = iso_forest.predict(features_scaled)\n",
        "\n",
        "        # Add the results to the DataFrame\n",
        "        filtered_sizes_df.loc[:, 'anomaly_score'] = anomaly_scores\n",
        "        filtered_sizes_df.loc[:, 'anomaly_label'] = anomaly_labels\n",
        "        filtered_sizes_df.loc[:, 'gmdnCode'] = str(gmdncode)\n",
        "\n",
        "        # Filter out potential anomalies (anomaly_label = -1 indicates anomaly)\n",
        "        anomalies = filtered_sizes_df[filtered_sizes_df['anomaly_label'] == -1].copy()\n",
        "\n",
        "        # Ensure 'PrimaryDI' and 'gmdnCode' are strings\n",
        "        anomalies['PrimaryDI'] = anomalies['PrimaryDI'].astype(str)\n",
        "        anomalies['gmdnCode'] = anomalies['gmdnCode'].astype(str)\n",
        "\n",
        "        # Select only the desired columns\n",
        "        anomalies_filtered = anomalies[['PrimaryDI', 'gmdnCode', 'anomaly_score']]\n",
        "\n",
        "        # Save the anomalies to CSV\n",
        "        if not anomalies_filtered.empty:\n",
        "            save_anomalies_to_csv(anomalies_filtered, file_path)\n",
        "\n",
        "    # Load and return the final anomalies\n",
        "    if os.path.exists(file_path):\n",
        "        all_anomalies_df = pd.read_csv(file_path, dtype={'PrimaryDI': str, 'gmdnCode': str})\n",
        "        return all_anomalies_df\n",
        "    else:\n",
        "        print(f\"No anomalies were found and saved in {file_path}.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "J9QPE8h3LzY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXAMPLE USAGE**"
      ],
      "metadata": {
        "id": "X8u_AplZNi5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Mode descriptions :\n",
        "\n",
        "1 : Trains models for every GMDN Code and saves the models + Uses these models for inference to output a file containing anomalous PrimaryDIs and the anomaly scores.\n",
        "(Use this when you're running the script for the first ever time)\n",
        "\n",
        "2 : Directly loads model from saved pickle files and makes inference for the current data batch\n",
        "(Use this only after you've run the entire code with MODE = 1 at least once)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Name of the folder where all the models and the final anomalies csv gets saved\n",
        "folder_name = 'anomalies_output'\n",
        "\n",
        "# Name of the anomalies file\n",
        "anomalies_file_name = 'final_anomalies.csv'"
      ],
      "metadata": {
        "id": "wDmoTuadNgsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To run in mode 1 (train and save models):\n",
        "final_anomalies_df = process_gmdn_codes(gmdn_df, vector_df, folder_name, anomalies_file_name, mode=1)\n",
        "\n",
        "# Print the final anomalies DataFrame\n",
        "if final_anomalies_df is not None:\n",
        "    print(\"\\n\")\n",
        "    print(final_anomalies_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qNvQgOUUXf4",
        "outputId": "064dbd1b-feb9-4575-ce5b-96c9ed30b00c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing gmdnCodes:   0%|          | 5/12927 [00:04<2:54:51,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "        PrimaryDI gmdnCode  anomaly_score\n",
            "0  00850014433642    33961      -0.000005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To run in mode 2 (load models and use them for inference):\n",
        "final_anomalies_df = process_gmdn_codes(gmdn_df, vector_df, folder_name, anomalies_file_name, mode=2)\n",
        "\n",
        "# Print the final anomalies DataFrame\n",
        "if final_anomalies_df is not None:\n",
        "    print(\"\\n\")\n",
        "    print(final_anomalies_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I9Py4IQSwrD",
        "outputId": "156ef3ed-f0dc-4fda-d39c-442c04d56bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing gmdnCodes:   0%|          | 5/12927 [00:03<2:16:42,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "        PrimaryDI gmdnCode  anomaly_score\n",
            "0  00850014433642    33961      -0.000005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}